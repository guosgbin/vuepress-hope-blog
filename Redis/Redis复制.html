<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.20" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.78" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://blog.guosgbin.cn/Redis/Redis%E5%A4%8D%E5%88%B6.html"><meta property="og:title" content="Redis复制"><meta property="og:description" content="本文内容来自 https://redis.io/docs/management/replication/ 《Redis 使用手册》 -- 可以 《Redis 开发和运维》-- 很棒 《Redis 深度历险》 -- 建议不看这个 Redis 复制 Redis 提供了复制功能， 实现了相同数据的多个 Redis 副本， 复制功能是高可用 Redis 的基础..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2025-04-03T07:07:29.000Z"><meta property="article:modified_time" content="2025-04-03T07:07:29.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Redis复制","image":[""],"dateModified":"2025-04-03T07:07:29.000Z","author":[{"@type":"Person","name":"超威蓝猫 Dylan Kwok","url":"","email":"guosgbin@163.com"}]}</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><link href="https://fonts.googleapis.com/css2?family=LXGW+WenKai+Mono+TC" rel="stylesheet"><link href="https://fonts.googleapis.com/css2?family=LXGW+WenKai+TC" rel="stylesheet"><link rel="icon" href="/小熊猫.svg"><title>Redis复制</title><meta name="description" content="本文内容来自 https://redis.io/docs/management/replication/ 《Redis 使用手册》 -- 可以 《Redis 开发和运维》-- 很棒 《Redis 深度历险》 -- 建议不看这个 Redis 复制 Redis 提供了复制功能， 实现了相同数据的多个 Redis 副本， 复制功能是高可用 Redis 的基础...">
    <link rel="preload" href="/assets/style-DJJ2bZ_d.css" as="style"><link rel="stylesheet" href="/assets/style-DJJ2bZ_d.css">
    <link rel="modulepreload" href="/assets/app-DePq4ozi.js"><link rel="modulepreload" href="/assets/Redis复制.html--dEfNmHI.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-D1HmjPqT.js" as="script"><link rel="prefetch" href="/assets/01-创建和销毁对象.html-za7Rq9t9.js" as="script"><link rel="prefetch" href="/assets/01-CAS和Unsafe的API分析.html-D7_-nKyZ.js" as="script"><link rel="prefetch" href="/assets/02-基本类型原子类AtomicLong.html-CT9B_KQD.js" as="script"><link rel="prefetch" href="/assets/03-引用类型原子类AtomicReference.html-2ZDOFh8S.js" as="script"><link rel="prefetch" href="/assets/04-原子数组类AtomicLongArray.html-BwlBIJ2V.js" as="script"><link rel="prefetch" href="/assets/05-原子操作类AtomicReferenceFieldUpdater.html-BvhP96qA.js" as="script"><link rel="prefetch" href="/assets/06-高性能原子类LongAdder.html-CYQiMKcc.js" as="script"><link rel="prefetch" href="/assets/07-LockSupport分析.html-TxRVj4NN.js" as="script"><link rel="prefetch" href="/assets/08-AQS简单介绍.html-COeHvPgu.js" as="script"><link rel="prefetch" href="/assets/09-基于ReentrantLock分析AQS的独占模式.html-gB97kukz.js" as="script"><link rel="prefetch" href="/assets/10-基于CountDownLatch分析AQS的共享模式.html-BSgtSlKk.js" as="script"><link rel="prefetch" href="/assets/11-AQS的Condition机制.html-DoJPW2JL.js" as="script"><link rel="prefetch" href="/assets/12-信号量Semaphore.html-BaxBmpB0.js" as="script"><link rel="prefetch" href="/assets/13-循环栏栅CyclicBarrier.html-CChYlnwq.js" as="script"><link rel="prefetch" href="/assets/14-阶段Phaser.html-bDXiLTfp.js" as="script"><link rel="prefetch" href="/assets/15-交换Exchanger.html-CPUG-B9R.js" as="script"><link rel="prefetch" href="/assets/16-读写锁ReentrantReadWriteLock.html-CF4d47GW.js" as="script"><link rel="prefetch" href="/assets/17-Future模式-FutureTask.html-CD14B1MX.js" as="script"><link rel="prefetch" href="/assets/18-线程池体系概述.html-CSxUPt7i.js" as="script"><link rel="prefetch" href="/assets/19-线程池体系-AbstractExecutorService.html-BTVWwFED.js" as="script"><link rel="prefetch" href="/assets/20-线程池体系-ThreadPoolExecutor.html-w--r1gG1.js" as="script"><link rel="prefetch" href="/assets/21-线程池体系-ScheduledThreadPoolExecutor.html-DLmdzmRE.js" as="script"><link rel="prefetch" href="/assets/22-CopyOnWriteArrayList写时复制.html-tZiVCmhK.js" as="script"><link rel="prefetch" href="/assets/23-CopyOnWriteArraySet写时复制.html-C-9CsPHr.js" as="script"><link rel="prefetch" href="/assets/24-ConcurrentSkipListMap跳表.html-B-B7-dI0.js" as="script"><link rel="prefetch" href="/assets/25-ConcurrentSkipListSet跳表.html-dxao2NJN.js" as="script"><link rel="prefetch" href="/assets/26-ConcurrentHashMap源码分析.html-X6bRvtii.js" as="script"><link rel="prefetch" href="/assets/27-阻塞队列ArrayBlockingQueue.html-CWPvXDWG.js" as="script"><link rel="prefetch" href="/assets/28-阻塞队列LinkedBlockingQueue.html-BOlydIar.js" as="script"><link rel="prefetch" href="/assets/29-阻塞队列LinkedBlockingDeque.html-CcEC12oH.js" as="script"><link rel="prefetch" href="/assets/30-阻塞队列PriorityBlockingQueue.html-hq_bYE6V.js" as="script"><link rel="prefetch" href="/assets/31-阻塞队列DelayQueue.html-qbfwdVgH.js" as="script"><link rel="prefetch" href="/assets/32-阻塞队列SynchronousQueue.html-DlMdaYXV.js" as="script"><link rel="prefetch" href="/assets/33-阻塞队列LinkedTransferQueue.html-CesxTGMH.js" as="script"><link rel="prefetch" href="/assets/SPI机制.html-CXjug_AB.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis01：myabtis的整体架构.html-Cyo-qyMq.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis02：入门案例.html-hgmnjGS7.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis03：解析全局配置文件.html-DA07cOym.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis04：解析Mapper映射文件.html-C9zZIHoj.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis05：解析Statement操作节点.html-CI306zEc.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis06：解析SQL语句.html-C-xjsm_A.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis07：Java方法和SQL语句绑定.html-DA6OxU3M.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis08：获得SqlSession.html-Kqj0IkE_.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis09：Executor执行器.html-HtA5pde4.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis10：缓存机制.html-VJpoBtTb.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis11：StatementHandler.html-87UW8wSn.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis12：参数解析和赋值.html-BllyKkzs.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis13：结果集处理.html-COvWCOFb.js" as="script"><link rel="prefetch" href="/assets/深入浅出Mybatis14：插件.html-xYVtHD7D.js" as="script"><link rel="prefetch" href="/assets/01-服务端启动流程.html-Qol3UnA5.js" as="script"><link rel="prefetch" href="/assets/02-服务端启动添加ChannelInitializer到管道.html-BGpIEWFt.js" as="script"><link rel="prefetch" href="/assets/03-客户端启动流程.html-b1GKbTf3.js" as="script"><link rel="prefetch" href="/assets/04-线程体系-NioEventLoopGroup.html-DWYnb9H_.js" as="script"><link rel="prefetch" href="/assets/05-线程体系-NioEventLoop相关父接口分析.html-BxjCKZ_K.js" as="script"><link rel="prefetch" href="/assets/06-线程体系-AbstractEventExecutor.html-CRN77ma4.js" as="script"><link rel="prefetch" href="/assets/07-线程体系-AbstractScheduledEventExecutor-优先队列.html--3kClJm0.js" as="script"><link rel="prefetch" href="/assets/08-线程体系-NioEventLoop概述.html-BUfOTwyr.js" as="script"><link rel="prefetch" href="/assets/09-线程体系-NioEventLoop开启Selector及优化.html-Br_zHykT.js" as="script"><link rel="prefetch" href="/assets/10-线程体系-NioEventLoop绑定线程.html-80UBKJwu.js" as="script"><link rel="prefetch" href="/assets/11-线程体系-NioEventLoop的run方法.html-Bh4gI4TM.js" as="script"><link rel="prefetch" href="/assets/12-线程体系-NioEventLoop规避JDK的NIO空循环bug.html-B8wT-PcJ.js" as="script"><link rel="prefetch" href="/assets/13-线程体系-NioEventLoop的优雅关闭.html-Cre3sGhq.js" as="script"><link rel="prefetch" href="/assets/14-服务端处理客户端的连接(ACCEPT).html-B0kW1esk.js" as="script"><link rel="prefetch" href="/assets/15-客户端处理READ事件概述.html-D6QEuCXf.js" as="script"><link rel="prefetch" href="/assets/16-客户端处理READ事件详解及RecvByteBufAllocator.html-B2mkAJ5Y.js" as="script"><link rel="prefetch" href="/assets/17-Netty管道机制.html-pBcUWIZs.js" as="script"><link rel="prefetch" href="/assets/18-Netty发送数据流程及出站缓冲区.html-DFIYAeqI.js" as="script"><link rel="prefetch" href="/assets/Redis_Benchmark基准测试.html-DlyQidb2.js" as="script"><link rel="prefetch" href="/assets/Redis_Cluster集群和槽管理命令.html-BCUPKiu7.js" as="script"><link rel="prefetch" href="/assets/Redis_Cluster集群基本特性和集群搭建.html-C1sMW2FW.js" as="script"><link rel="prefetch" href="/assets/Redis_Cluster集群管理工具redis-cli.html-C3LRy12f.js" as="script"><link rel="prefetch" href="/assets/Redis_Pipeline优化RTT.html-CgZcTFRz.js" as="script"><link rel="prefetch" href="/assets/Redis_Sentinel高可用.html-ZUnP6Ivg.js" as="script"><link rel="prefetch" href="/assets/Redis_key设计规范.html-sYrnOGp9.js" as="script"><link rel="prefetch" href="/assets/Redis事务.html-BmZp19sR.js" as="script"><link rel="prefetch" href="/assets/Redis内存淘汰策略.html-x-qyeKrA.js" as="script"><link rel="prefetch" href="/assets/Redis发布订阅.html-BrnW-uLq.js" as="script"><link rel="prefetch" href="/assets/Redis大key和热key问题.html-BOPGpsKU.js" as="script"><link rel="prefetch" href="/assets/Redis慢查询日志.html-ChXb7lGL.js" as="script"><link rel="prefetch" href="/assets/Redis持久化机制.html-DLAOXhY2.js" as="script"><link rel="prefetch" href="/assets/Redis键空间通知(keyspace notification).html-CgYBhLR7.js" as="script"><link rel="prefetch" href="/assets/redis-cli 使用.html-DHQHG_5W.js" as="script"><link rel="prefetch" href="/assets/01-RocketMQ概述.html-C--qt7nU.js" as="script"><link rel="prefetch" href="/assets/02-NameServer启动流程.html-BEQg38-C.js" as="script"><link rel="prefetch" href="/assets/03-Broker启动流程.html-C_PND05M.js" as="script"><link rel="prefetch" href="/assets/04-RocketMQ网络通信原理.html-BMP1JgK3.js" as="script"><link rel="prefetch" href="/assets/05-RocketMQ 服务端和客户端的启动.html-DgiBjG-e.js" as="script"><link rel="prefetch" href="/assets/06-RocketMQ网络通信源码.html-CH82Z-vY.js" as="script"><link rel="prefetch" href="/assets/07-NameServer作用和路由元信息.html-BiKXE6fK.js" as="script"><link rel="prefetch" href="/assets/08-NameServer路由管理源码分析.html-6ls3ELB_.js" as="script"><link rel="prefetch" href="/assets/09-生产者相关类分析.html-BB4Uiggw.js" as="script"><link rel="prefetch" href="/assets/10-生产者启动流程.html-B0fImC9N.js" as="script"><link rel="prefetch" href="/assets/11-生产者发送消息.html-CZYyH-hB.js" as="script"><link rel="prefetch" href="/assets/12-Broker存储机制概述.html-BROwZohm.js" as="script"><link rel="prefetch" href="/assets/13-MappedFile和MappedFileQueue分析.html-CIyinEg4.js" as="script"><link rel="prefetch" href="/assets/14-CommitLog原理分析.html-BDqMvbR0.js" as="script"><link rel="prefetch" href="/assets/15-broker的刷盘机制.html-Bfq9IF7I.js" as="script"><link rel="prefetch" href="/assets/16-ConsumeQueue和Index原理分析.html-CjbS_9a_.js" as="script"><link rel="prefetch" href="/assets/17-broker过期文件删除机制.html-DPl194wx.js" as="script"><link rel="prefetch" href="/assets/18-消费者启动流程(TODO).html-DrraF0dB.js" as="script"><link rel="prefetch" href="/assets/19-消息拉取入口和消息队列负载均衡.html-KCpw0Dkp.js" as="script"><link rel="prefetch" href="/assets/20-消费者发送消息拉取请求流程.html-CJI3BXNK.js" as="script"><link rel="prefetch" href="/assets/21-broker处理消息拉取请求-1-主流程.html-bHjQcoC-.js" as="script"><link rel="prefetch" href="/assets/22-broker处理消息拉取请求-2-长轮询.html-Dcm7fqpu.js" as="script"><link rel="prefetch" href="/assets/23-broker处理消息拉取请求-3-读取消息.html-BVKwrhy_.js" as="script"><link rel="prefetch" href="/assets/24-消费者处理从broker拉取的消息.html-M0cE4FUi.js" as="script"><link rel="prefetch" href="/assets/25-并发消费原理.html-BYgosR01.js" as="script"><link rel="prefetch" href="/assets/001-服务器CPU问题-规律性峰刺.html-CflYhTY1.js" as="script"><link rel="prefetch" href="/assets/002-服务器CPU配置降低GC分析.html-93lAcWMA.js" as="script"><link rel="prefetch" href="/assets/003-服务器CPU使用率较低但系统负载高.html-ByzbbQfh.js" as="script"><link rel="prefetch" href="/assets/004-log4j2内存泄露导致的频繁fullgc.html-UJVb05Fj.js" as="script"><link rel="prefetch" href="/assets/005-线程池父子任务使用不当造成死锁.html-CqkfEM7S.js" as="script"><link rel="prefetch" href="/assets/006-linux系统参数-连接队列长度过小导致连接丢弃.html-ZMzPyE1s.js" as="script"><link rel="prefetch" href="/assets/007-redis频繁淘汰-清除redis线上未设置过期时间的key.html-nXPS9TZR.js" as="script"><link rel="prefetch" href="/assets/008-JVM堆外内存泄露排查.html-C2BmNK-E.js" as="script"><link rel="prefetch" href="/assets/IM如何保证消息不丢失.html-muGarKkc.js" as="script"><link rel="prefetch" href="/assets/经验-查询类接口超时优化技巧.html-DlPCle6Y.js" as="script"><link rel="prefetch" href="/assets/项目-IM长连接优化.html-Din5yjW4.js" as="script"><link rel="prefetch" href="/assets/项目-服务降级.html-DFO77xo1.js" as="script"><link rel="prefetch" href="/assets/项目-直播间业务多级缓存优化.html-RgboFAb2.js" as="script"><link rel="prefetch" href="/assets/项目-线程池优化.html-IwlzhNIo.js" as="script"><link rel="prefetch" href="/assets/JUC相关问题.html-DAT-dsXj.js" as="script"><link rel="prefetch" href="/assets/JVM问题.html-YgXjc1Et.js" as="script"><link rel="prefetch" href="/assets/MySQL相关问题.html-Dqnw1WbM.js" as="script"><link rel="prefetch" href="/assets/Redis相关问题.html-Dz105oz8.js" as="script"><link rel="prefetch" href="/assets/二分查找.html-C0iAN8k_.js" as="script"><link rel="prefetch" href="/assets/二叉树.html-B6AdSlqr.js" as="script"><link rel="prefetch" href="/assets/代码随想录题目目录.html-DkAWzICQ.js" as="script"><link rel="prefetch" href="/assets/HowToSayResume.html-CbfLbw-t.js" as="script"><link rel="prefetch" href="/assets/index.html-ttOYcLxs.js" as="script"><link rel="prefetch" href="/assets/resume.html-Bg4V_YcH.js" as="script"><link rel="prefetch" href="/assets/404.html-CLkhUkcv.js" as="script"><link rel="prefetch" href="/assets/index.html-LqnJiIQb.js" as="script"><link rel="prefetch" href="/assets/index.html-Cahn3LsA.js" as="script"><link rel="prefetch" href="/assets/index.html-I_47fi89.js" as="script"><link rel="prefetch" href="/assets/index.html-CBwu0hid.js" as="script"><link rel="prefetch" href="/assets/index.html-BXyE5TQ5.js" as="script"><link rel="prefetch" href="/assets/index.html-CBz9L1hr.js" as="script"><link rel="prefetch" href="/assets/index.html-D6P8k8b2.js" as="script"><link rel="prefetch" href="/assets/index.html-B17Ejuyv.js" as="script"><link rel="prefetch" href="/assets/index.html-ClHDjS1j.js" as="script"><link rel="prefetch" href="/assets/index.html-DcyrT4up.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-BUCVUXiE.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-DXWKOczD.js" as="script"><link rel="prefetch" href="/assets/giscus-BwIGYrs0.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="Take me home"><img class="vp-nav-logo" src="/小熊猫.svg" alt><!----><!----></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="超威蓝猫小站" iconsizing="height"><!---->超威蓝猫小站<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/guosgbin/vuepress-blog" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-outlook-dropdown"><!----></div></button></div><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis_Benchmark%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95.html" aria-label="Redis Benchmark基准测试" iconsizing="both"><!---->Redis Benchmark基准测试<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis_Cluster%E9%9B%86%E7%BE%A4%E5%92%8C%E6%A7%BD%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4.html" aria-label="Redis Cluster集群和槽管理命令" iconsizing="both"><!---->Redis Cluster集群和槽管理命令<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis_Cluster%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7%E5%92%8C%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.html" aria-label="Redis Cluster集群基本特性和集群搭建" iconsizing="both"><!---->Redis Cluster集群基本特性和集群搭建<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis_Cluster%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7redis-cli.html" aria-label="Redis Cluster集群管理工具redis-cli" iconsizing="both"><!---->Redis Cluster集群管理工具redis-cli<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis_key%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83.html" aria-label="Redis key设计规范" iconsizing="both"><!---->Redis key设计规范<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis_Pipeline%E4%BC%98%E5%8C%96RTT.html" aria-label="Redis Pipeline优化RTT" iconsizing="both"><!---->Redis Pipeline优化RTT<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis_Sentinel%E9%AB%98%E5%8F%AF%E7%94%A8.html" aria-label="Redis Sentinel高可用" iconsizing="both"><!---->Redis Sentinel高可用<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/redis-cli%20%E4%BD%BF%E7%94%A8.html" aria-label="redis-cli使用" iconsizing="both"><!---->redis-cli使用<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis%E4%BA%8B%E5%8A%A1.html" aria-label="Redis事务" iconsizing="both"><!---->Redis事务<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5.html" aria-label="Redis内存淘汰策略" iconsizing="both"><!---->Redis内存淘汰策略<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85.html" aria-label="Redis发布订阅" iconsizing="both"><!---->Redis发布订阅<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/Redis/Redis%E5%A4%8D%E5%88%B6.html" aria-label="Redis复制" iconsizing="both"><!---->Redis复制<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis%E5%A4%A7key%E5%92%8C%E7%83%ADkey%E9%97%AE%E9%A2%98.html" aria-label="Redis大key和热key问题" iconsizing="both"><!---->Redis大key和热key问题<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97.html" aria-label="Redis慢查询日志" iconsizing="both"><!---->Redis慢查询日志<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6.html" aria-label="Redis持久化机制" iconsizing="both"><!---->Redis持久化机制<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/Redis/Redis%E9%94%AE%E7%A9%BA%E9%97%B4%E9%80%9A%E7%9F%A5(keyspace%20notification).html" aria-label="Redis键空间通知" iconsizing="both"><!---->Redis键空间通知<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Redis复制</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">超威蓝猫 Dylan Kwok</span></span><span property="author" content="超威蓝猫 Dylan Kwok"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">April 3, 2025</span><meta property="datePublished" content="2025-04-03T07:07:29.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 34 min</span><meta property="timeRequired" content="PT34M"></span><!----><!----></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><table><thead><tr><th>版本</th><th>内容</th><th>时间</th></tr></thead><tbody><tr><td>V1</td><td>新建</td><td>2023年04月02日00:44:03</td></tr></tbody></table><p>本文内容来自</p><ol><li><a href="https://redis.io/docs/management/replication/" target="_blank" rel="noopener noreferrer">https://redis.io/docs/management/replication/</a></li><li>《Redis 使用手册》 -- 可以</li><li>《Redis 开发和运维》-- 很棒</li><li>《Redis 深度历险》 -- 建议不看这个</li></ol><h2 id="redis-复制" tabindex="-1"><a class="header-anchor" href="#redis-复制"><span>Redis 复制</span></a></h2><p>Redis 提供了复制功能， 实现了相同数据的多个 Redis 副本， 复制功能是高可用 Redis 的基础。</p><p>参与复制的 Redis 分为主节点（master），从节点（slave 或者 replica）。</p><p>对于 Redis 来说</p><ul><li>一个主节点可以拥有多个从节点，从节点本身也可以作为其他节点的主节点；</li><li>一个从节点只能有一个主节点；</li></ul><p>默认情况下处于复制模式的主节点可以读写，从节点只能读（可配置）。</p><p>Redis 的复制的优点有哪些？</p><ol><li>性能方面：Redis 的复制功能可以给系统的读性能带来线性级别的提升。一般来说用户每增加一倍数量的从节点，整个系统的读性能就能提升一倍；</li><li>安全性：增加从节点的数量，可以进行主节点的故障转移；</li><li>高可用：使用 Redis 的复制功能和 Sentinel 功能，可以为整个 Redis 服务提供高可用特性；</li></ol><h2 id="cap-理论" tabindex="-1"><a class="header-anchor" href="#cap-理论"><span>CAP 理论</span></a></h2><ul><li>C : Consistent ， 一致性；</li><li>A : Availability ， 可用性；</li><li>P : Partition tolerance ，分区容错性；</li></ul><p>分布式系统的节点往往都是分布在不同的机器上进行网络隔离开的 ， 这意味着必然会有网络断开的风险 ， 这个网络断开的场景的专业词汇叫作<strong>网络分区</strong>。</p><p>在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操作将无法同步到另外一个节点，所以数据的<strong>一致性</strong>将无法满足 ， 因为两个分布式节点的数据不再保持一致。除非我们牺牲<strong>可用性</strong>，也就是暂停分布式节点服务 ， 在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务 。</p><p>简单来说就是<strong>当网络分区发生时 ， 一致性和可用性只能保证一个</strong>。</p><h2 id="配置相关" tabindex="-1"><a class="header-anchor" href="#配置相关"><span>配置相关</span></a></h2><h3 id="建立复制" tabindex="-1"><a class="header-anchor" href="#建立复制"><span>建立复制</span></a></h3><p>5.0.0 之前 Redis 一直使用 slaveof 作为复制命令，从 5.0.0 版本开始出现了新的复制命令 replicaof，并逐渐废弃原来的 slaveof 命令。</p><p>有三种方式建立复制</p><ul><li>直接使用 slaveof 或者 replicaof 命令，让当前节点作为某个节点的从节点；</li><li>在配置文件在指定主节点的 ip 和端口；</li><li>在 redis-server 启动命令后加入启动参数指定主节点的 ip 和端口；</li></ul><p>目前我在本地开了两个 Redis 进程，端口分别是 6379 和 10086，将 10086 端口的 Redis 作为 6379 的从节点。</p><h4 id="动态指定" tabindex="-1"><a class="header-anchor" href="#动态指定"><span>动态指定</span></a></h4><p>直接使用 slaveof 或者 replicaof 命令</p><blockquote><p><a href="https://redis.io/commands/slaveof/" target="_blank" rel="noopener noreferrer">https://redis.io/commands/slaveof/</a></p><p><a href="https://redis.io/commands/replicaof/" target="_blank" rel="noopener noreferrer">https://redis.io/commands/replicaof/</a></p></blockquote><p>在 10086 Redis 的客户端输入命令</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>127.0.0.1:10086&gt; replicaof 127.0.0.1 6379</span></span>
<span class="line"><span>OK</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>主节点日志</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>67690:M 01 Apr 2023 23:57:31.566 * Replica 127.0.0.1:10086 asks for synchronization</span></span>
<span class="line"><span>67690:M 01 Apr 2023 23:57:31.566 * Partial resynchronization not accepted: Replication ID mismatch (Replica asked for &#39;14bd5efcae1e1bd1ed075eb2751db292a9a32cb0&#39;, my replication IDs are &#39;2e11109e0e9d006c4204cfac232598c83c125a77&#39; and &#39;0000000000000000000000000000000000000000&#39;)</span></span>
<span class="line"><span>67690:M 01 Apr 2023 23:57:31.566 * Replication backlog created, my new replication IDs are &#39;9fb57f9dd2175483564aef99f825bcf4a4d549a7&#39; and &#39;0000000000000000000000000000000000000000&#39;</span></span>
<span class="line"><span>67690:M 01 Apr 2023 23:57:31.567 * Starting BGSAVE for SYNC with target: disk</span></span>
<span class="line"><span>67690:M 01 Apr 2023 23:57:31.572 * Background saving started by pid 68439</span></span>
<span class="line"><span>68439:C 01 Apr 2023 23:57:31.573 * DB saved on disk</span></span>
<span class="line"><span>67690:M 01 Apr 2023 23:57:31.581 * Background saving terminated with success</span></span>
<span class="line"><span>67690:M 01 Apr 2023 23:57:31.581 * Synchronization with replica 127.0.0.1:10086 succeeded</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>从节点日志</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>67813:S 01 Apr 2023 23:57:31.561 * Before turning into a replica, using my own master parameters to synthesize a cached master: I may be able to synchronize with the new master with just a partial transfer.</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.562 * Connecting to MASTER 127.0.0.1:6379</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.562 * MASTER &lt;-&gt; REPLICA sync started</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.562 * REPLICAOF 127.0.0.1:6379 enabled (user request from &#39;id=3 addr=127.0.0.1:63385 laddr=127.0.0.1:10086 fd=8 name= age=339 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=44 qbuf-free=65486 argv-mem=22 obl=0 oll=0 omem=0 tot-mem=82998 events=r cmd=replicaof user=default redir=-1&#39;)</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.563 * Non blocking connect for SYNC fired the event.</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.565 * Master replied to PING, replication can continue...</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.565 * Trying a partial resynchronization (request 14bd5efcae1e1bd1ed075eb2751db292a9a32cb0:1).</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.572 * Full resync from master: 9fb57f9dd2175483564aef99f825bcf4a4d549a7:0</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.572 * Discarding previously cached master state.</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.581 * MASTER &lt;-&gt; REPLICA sync: receiving 176 bytes from master to disk</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.581 * MASTER &lt;-&gt; REPLICA sync: Flushing old data</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.581 * MASTER &lt;-&gt; REPLICA sync: Loading DB in memory</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.582 * Loading RDB produced by version 6.2.11</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.582 * RDB age 0 seconds</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.582 * RDB memory usage when created 2.08 Mb</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.582 # Done loading RDB, keys loaded: 0, keys expired: 0.</span></span>
<span class="line"><span>67813:S 01 Apr 2023 23:57:31.582 * MASTER &lt;-&gt; REPLICA sync: Finished with success</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>这里主要说下上面日志中的 C、M、S 表示什么</p><ol><li>C 表示是子进程打出来的日志；</li><li>M 表示是 Master 节点的日志；</li><li>S 表示是 Slave 节点的日志；</li></ol></blockquote><p>这样主从节点就配置好了。</p><p>slaveof 和 replicaof 都是异步命令，执行命令时， 当前节点只保存主节点信息后返回， 后续复制流程在节点内部异步执行。</p><p>通过 info replication 命令查看主从节点的状态</p><p>主节点：</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1:6379&gt; info replication</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Replication</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">role:master							</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 当前节点的角色</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">connected_slaves:1					</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 连接的从节点个数</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave0:</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">ip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">port</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">10086,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">state</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">online,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">offset</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">266,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">lag</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">1 </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># id、IP地址、端口、状态、偏移量、滞后</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_failover_state:no-failover	</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 正在进行的故障转移的状态（如果有）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_replid:02d649b60886a53ba1b19483707045bd0c2e8fd7	</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 当前节点的复制ID </span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_replid2:0000000000000000000000000000000000000000	</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 辅助复制ID，用于故障转移后的 PSYNC 命令</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_repl_offset:266				</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 节点当前复制偏移量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">second_repl_offset:-1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_active:1				</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 标识复制积压的标志处于活动状态</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_size:1048576			</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 复制积压缓冲区的总大小（以字节为单位）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_first_byte_offset:1 	</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 复制积压缓冲区的主偏移量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_histlen:266			</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 复制积压缓冲区中数据的大小（以字节为单位）</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>从节点：</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1:10086&gt; info replication</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Replication</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">role:slave							</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 当前节点的角色</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_host:127.0.0.1				</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 主节点的 ip</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_port:6379					</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 主节点的端口</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_link_status:up				</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 连接状态 up/down</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_last_io_seconds_ago:3		</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 上次与 master 交互的间隔秒数</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_sync_in_progress:0			</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 表示主节点正在同步到副本</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave_read_repl_offset:280			</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 从节点的读复制偏移量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave_repl_offset:280				</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 从节点的复制偏移量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave_priority:100					</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 从节点作为故障转移候选者的优先级</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave_read_only:1					</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 从节点是否为只读的标志</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">replica_announced:1					</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 从节点是否由 Sentinel 宣布的标志</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">connected_slaves:0					</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 连接的从节点个数</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_failover_state:no-failover	</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 正在进行的故障转移的状态（如果有）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_replid:02d649b60886a53ba1b19483707045bd0c2e8fd7	</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 当前节点的复制ID </span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_replid2:0000000000000000000000000000000000000000 </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 辅助复制ID，用于故障转移后的 PSYNC 命令</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_repl_offset:280				</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 节点当前复制偏移量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">second_repl_offset:-1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_active:1				</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 标识复制积压的标志处于活动状态</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_size:1048576			</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 复制积压缓冲区的总大小（以字节为单位）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_first_byte_offset:1 	</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 复制积压缓冲区的主偏移量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_histlen:280			</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 复制积压缓冲区中数据的大小（以字节为单位）</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="配置文件指定" tabindex="-1"><a class="header-anchor" href="#配置文件指定"><span>配置文件指定</span></a></h4><p>在配置文件加上这个配置项</p><ul><li>Redis 5 之前是 <code> slaveof &lt;masterip&gt; &lt;masterport&gt;</code></li><li>Reids 5 之后是 <code>replicaof &lt;masterip&gt; &lt;masterport&gt;</code></li></ul><p>这里我指定 6379 端口作为当前节点的主节点</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">replicaof 127.0.0.1 6379</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="redis-server-启动命令指定" tabindex="-1"><a class="header-anchor" href="#redis-server-启动命令指定"><span>redis-server 启动命令指定</span></a></h4><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>./redis-server  --replicaof 127.0.0.1 6379</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="取消复制" tabindex="-1"><a class="header-anchor" href="#取消复制"><span>取消复制</span></a></h3><p>在将一个节点设置为从节点之后，可通过下面的命令，让从节点停止复制，重新变成主节点。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>replicaof no one</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>或者</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>salveof no one</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>节点在停止复制之后不会清空数据库，而是继续保留复制产生的所有数据。</strong></p><p>操作一下：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>127.0.0.1:10086&gt; slaveof no one</span></span>
<span class="line"><span>OK</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>主节点日志</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>69576:M 02 Apr 2023 00:39:59.503 # Connection with replica 127.0.0.1:10086 lost.</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>从节点日志，可以看到这个节点的日志的从前面的 S 变成了 M。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>69865:M 02 Apr 2023 00:39:59.502 # Connection with master lost.</span></span>
<span class="line"><span>69865:M 02 Apr 2023 00:39:59.502 * Caching the disconnected master state.</span></span>
<span class="line"><span>69865:M 02 Apr 2023 00:39:59.502 * Discarding previously cached master state.</span></span>
<span class="line"><span>69865:M 02 Apr 2023 00:39:59.503 # Setting secondary replication ID to 02d649b60886a53ba1b19483707045bd0c2e8fd7, valid up to offset: 2087. New replication ID is bf5cb4acb80123f1422fb780043a9b79f20017ae</span></span>
<span class="line"><span>69865:M 02 Apr 2023 00:39:59.503 * MASTER MODE enabled (user request from &#39;id=5 addr=127.0.0.1:63961 laddr=127.0.0.1:10086 fd=9 name= age=1476 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=34 qbuf-free=65496 argv-mem=12 obl=0 oll=0 omem=0 tot-mem=82988 events=r cmd=slaveof user=default redir=-1&#39;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通过取消复制的命令，我们可以实现切主的操作，重新和一个节点建立复制关系。不过需要注意的是，我们需要保存好数据，因为切主操作会清空当前节点内存中的数据。</p><h3 id="主从复制密码校验" tabindex="-1"><a class="header-anchor" href="#主从复制密码校验"><span>主从复制密码校验</span></a></h3><p>一般情况下主节点都会通过下面的配置项设置登录密码</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>requirepass 密码</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这时假如某个节点需要和主节点建立复制连接，作为从节点需要在配置文件中配置主节点的密码才能建立连接</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>masterauth 主节点密码</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="从节点设置只读" tabindex="-1"><a class="header-anchor" href="#从节点设置只读"><span>从节点设置只读</span></a></h3><p>redis 5 以上的配置</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>replica-read-only yes</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>redis 5 一下的配置</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>slave-read-only yes</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这时假如想在从节点写操作就会报错</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>(error) READONLY You can&#39;t write against a read only replica.</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="复制架构" tabindex="-1"><a class="header-anchor" href="#复制架构"><span>复制架构</span></a></h2><p>对于 Redis 来说，一个主节点可以拥有任意多个从节点，而从节点本身也可以用作其他节点的主节点。也就是说支持单层和多层复制关系。</p><p>可以分为下面几种一主一从、一主多从、树状主从结构。</p><h3 id="一主一从" tabindex="-1"><a class="header-anchor" href="#一主一从"><span>一主一从</span></a></h3><p>一主一从部署架构主要作用于故障转移。</p><p>当应用的写操作的并发量比较高且需要持久化时，可以只在从节点上面开启 AOF，这样既可以保证数据安全，也提高了主节点的性能。</p><h3 id="一主多从-星型复制架构" tabindex="-1"><a class="header-anchor" href="#一主多从-星型复制架构"><span>一主多从（星型复制架构）</span></a></h3><p>星型复制架构可以使得应用端利用多个从节点实现读写分离。</p><ul><li>所有只读节点均具备容灾功能，可作为备节点进行数据备份。</li><li>只读节点均从主节点同步数据，为星型复制架构，数据同步延迟远小于链式复制架构。</li></ul><img src="/assets/image-20230402155532164-BabWvULm.png" alt="image-20230402155532164" style="zoom:50%;"><h3 id="树状结构-链式复制架构" tabindex="-1"><a class="header-anchor" href="#树状结构-链式复制架构"><span>树状结构（链式复制架构）</span></a></h3><p>树状主从结构，从节点不仅可以复制主节点的数据，同时从节点也能作为其他从节点的主节点。这样的好处就是可以减少主节点的负载和需要传送给从节点的数据量。</p><p>需要注意的是只读节点采取链式复制架构，当只读节点数越多，<strong>靠近链路末端的只读节点数据延迟越大</strong>。</p><img src="/assets/image-20230402155548435-r3zzPPYl.png" alt="image-20230402155548435" style="zoom:50%;"><h2 id="查看节点角色-role" tabindex="-1"><a class="header-anchor" href="#查看节点角色-role"><span>查看节点角色 ROLE</span></a></h2><blockquote><p><a href="https://redis.io/commands/role/" target="_blank" rel="noopener noreferrer">https://redis.io/commands/role/</a></p></blockquote><h3 id="主节点的输出" tabindex="-1"><a class="header-anchor" href="#主节点的输出"><span>主节点的输出</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>1) &quot;master&quot;</span></span>
<span class="line"><span>2) (integer) 3129659</span></span>
<span class="line"><span>3) 1) 1) &quot;127.0.0.1&quot;</span></span>
<span class="line"><span>      2) &quot;10086&quot;</span></span>
<span class="line"><span>      3) &quot;3129242&quot;</span></span>
<span class="line"><span>   2) 1) &quot;127.0.0.1&quot;</span></span>
<span class="line"><span>      2) &quot;10000&quot;</span></span>
<span class="line"><span>      3) &quot;3129543&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>由三个元素组成结果</p><ul><li>第一个元素 master 表示当前节点是主节点；</li><li>第二个元素是主节点的复制偏移量（replication offset），记录了主节点目前向复制数据流发送的数据数量；</li><li>第三个元素是个数组：记录了主节点下面的所有从节点 <ul><li>第一个元素：从节点 IP 地址；</li><li>第二个元素：从节点端口号；</li><li>第三个元素：从节点的复制偏移量。从节点的复制偏移量记录了从节点通过复制数据流接收到的数据数量，从节点的复制偏移量与主节点的复制偏移量保持一致时，它们的数据就是一致的；</li></ul></li></ul><h3 id="从节点的输出" tabindex="-1"><a class="header-anchor" href="#从节点的输出"><span>从节点的输出</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>1) &quot;slave&quot;</span></span>
<span class="line"><span>2) &quot;127.0.0.1&quot;</span></span>
<span class="line"><span>3) (integer) 10086</span></span>
<span class="line"><span>4) &quot;connected&quot;</span></span>
<span class="line"><span>5) (integer) 3167038</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>第一个元素 slave 表示当前节点是从节点；</li><li>第二个元素：从节点 IP 地址；</li><li>第三个元素：从节点端口号；</li><li>第四个元素：主节点和从节点的当前连接状态，这个状态的值有下面 <ul><li>none：主从节点尚未建立连接；</li><li>connect：主从节点正在握手；</li><li>connecting：主从节点成功建立了连接；</li><li>sync：主从节点正在进行数据同步；</li><li>connected：主从节点已进入在线更新状态；</li><li>unkown：主从节点连接状态未知；</li></ul></li><li>第五个元素：从节点的复制偏移量。从节点的复制偏移量记录了从节点通过复制数据流接收到的数据数量，从节点的复制偏移量与主节点的复制偏移量保持一致时，它们的数据就是一致的；</li></ul><h3 id="哨兵节点输出" tabindex="-1"><a class="header-anchor" href="#哨兵节点输出"><span>哨兵节点输出</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>1) &quot;sentinel&quot;</span></span>
<span class="line"><span>2) 1) &quot;resque-master&quot;</span></span>
<span class="line"><span>   2) &quot;html-fragments-master&quot;</span></span>
<span class="line"><span>   3) &quot;stats-master&quot;</span></span>
<span class="line"><span>   4) &quot;metadata-master&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>字符串 sentinel。</li><li>此 Sentinel 实例监控的主节点名称的数组。</li></ul><h2 id="复制-id-说明" tabindex="-1"><a class="header-anchor" href="#复制-id-说明"><span>复制 ID 说明</span></a></h2><p>实例实际上有两个复制 ID：主 ID和辅助的 ID。</p><p>复制 ID 基本上标记了数据集的给定历史记录。每次一个实例从头开始作为主节点重新启动，或者一个副本被提升为主节点，都会为该实例生成一个新的复制 ID。连接到主节点的副本将在握手后继承其复制 ID。因此，具有相同 复制 ID 的两个实例之间的关系在于它们持有相同的数据，但可能在不同的时间。偏移量作为逻辑时间来理解，在给定的历史记录（复制ID）中，谁持有最新的数据集。</p><p>例如，如果两个实例A和B具有相同的复制ID，但一个偏移量为1000，另一个偏移量为1023，这意味着第一个实例缺少应用于数据集的某些命令。这也意味着A只需应用少量命令，就可以达到与B完全相同的状态。</p><p>Redis 主节点有两个复制 ID，一个是主 ID，另一个是辅助 ID。主 ID 是 Redis 主节点的当前复制 ID，用于标识 Redis 主节点当前的复制历史记录。而辅助 ID 则是用于在 Redis 主节点进行故障转移后，辅助 Redis 副本正确同步数据所需的复制 ID。当 Redis 主节点进行故障转移时，新的主节点会生成一个新的复制 ID 来标识新的复制历史记录，同时将旧的复制 ID 作为辅助 ID 存储在主节点中。这样，其他副本就可以使用辅助 ID 来正确地进行同步，而不会与旧的历史记录混淆。同时，主 ID 也会更新为新的复制 ID 以确保所有实例都使用正确的复制 ID。因此，Redis 主节点的 info replication 命令会显示两个复制 ID，以便管理员可以了解主节点当前的复制历史记录，并在故障转移后确认副本是否正确同步。</p><p>如果您想知道为什么在故障转移后提升为主节点的副本需要更改其复制ID：可能是由于某些网络分区的原因，旧主节点仍然作为主节点运行：保留相同的复制ID将违反任意两个随机实例具有相同数据集的相同ID和相同偏移量的事实。</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1:6379&gt; info replication</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Replication</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">role:master</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">connected_slaves:2</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave0:</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">ip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">port</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">10086,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">state</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">online,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">offset</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">28207,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">lag</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave1:</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">ip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">port</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">0,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">state</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">online,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">offset</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">0,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">lag</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">18852</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_failover_state:no-failover</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_replid:8909d9d2679658bbd539da23ca2f242428fcb25d</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_replid2:0000000000000000000000000000000000000000</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_repl_offset:28207</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">second_repl_offset:-1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_active:1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_size:1048576</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_first_byte_offset:1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_histlen:28207</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="数据同步" tabindex="-1"><a class="header-anchor" href="#数据同步"><span>数据同步</span></a></h2><h3 id="复制过程" tabindex="-1"><a class="header-anchor" href="#复制过程"><span>复制过程</span></a></h3><ul><li><p><strong>保存主节点信息</strong>；</p></li><li><p><strong>主从建立 socket 连接</strong>：</p><p>从节点内部通过每秒运行的定时任务维护复制相关逻辑，当定时任务发现存在新的主节点后，会尝试与该节点建立网络连接。连接成功后从节点打印下面的日志</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>75102:S 02 Apr 2023 15:36:43.820 * Connecting to MASTER 127.0.0.1:6379</span></span>
<span class="line"><span>75102:S 02 Apr 2023 15:36:43.820 * MASTER &lt;-&gt; REPLICA sync started</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>如果从节点无法建立连接，定时任务会无限重试直到连接成功或者执行取消连接的命令。</p></li><li><p><strong>发送 ping 命令</strong></p><p>连接建立成功后从节点发送 ping 请求进行首次通信，ping 的目的是检查主从之间网络套接字是否可用、检测主节点当前是否可以接收处理命令。如果从节点发送 ping 命令后，丛及诶单没有接收到主节点的 pong 或者超时，从节点会断开复制连接，下次定时任务会发起重连。</p><p>从节点获得到主节点的 pong 后会打印下面的日志</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>75102:S 02 Apr 2023 15:36:43.820 * Master replied to PING, replication can continue...</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li><li><p><strong>权限验证。</strong></p><p>如果主节点设置了 requirepass 参数，则需要密码验证。从节点需要配置 masterauth；</p></li><li><p><strong>同步数据</strong></p><p>主从复制连接正常通信后，对于首次建立复制的场景，主节点会把它的数据全部发送给从节点。</p></li><li><p><strong>命令持续复制</strong></p><p>当主节点把当前的数据同步给从节点后，便完成了复制的建立流程。接下来主节点会持续的把写命令发送给从节点，保存主从数据一致性。</p></li></ul><h3 id="数据同步-1" tabindex="-1"><a class="header-anchor" href="#数据同步-1"><span>数据同步</span></a></h3><p>数据同步分为完整同步、在线更新、部分同步。</p><ul><li>完整同步：一般用于建立连接初次复制的场景；</li><li>部分同步：Redis 2.8 以后提供了部分同步的功能；</li><li>在线更新：就是每当主节点执行一个写命令后，主节点会将相同的写命令或者具有相同效果的写命令发送给从节点；</li></ul><h4 id="完整同步" tabindex="-1"><a class="header-anchor" href="#完整同步"><span>完整同步</span></a></h4><p>当一个 Redis 节点接收到 replicaof、slaveof 命令，开始对另一个服务器进行复制时：</p><ul><li>从节点发送 psync 命令（旧版本是 sync）给主节点，发送从节点的旧主复制 ID 和它们到目前为止处理的偏移量，主节点根据自己的状态决定是完整同步还是部分同步；</li><li>主节点执行 bgsave 命令，生成一个 RDB 文件，并使用缓冲区存储 bgsave 命令之后执行的所有写命令；</li><li>当 RDB 文件创建完毕，主节点会通过套接字将 RDB 文件传送给从节点；</li><li>从节点在接收完主节点传送过来的 RDB 文件之后，先清空自己的数据库，然后载入这个 RDB 文件，从而获得主节点在执行 bgsave 命令时的所有数据；</li><li>当从节点完成 RDB 文件的加载动作后，并开始接收命令请求时，主节点会把之前存储在缓冲区中的所有写命令发送给从节点执行；如果主节点创建和传输 RDB 的时间过长， 对于高流量写入场景非常容易造成主节点复制客户端缓冲区溢出。 默认配置为 clientoutput-buffer-limit slave 256MB 64MB 60， 如果 60 秒内缓冲区消耗持续大于 64MB 或者直接超过 256MB 时， 主节点将直接关闭复制客户端连接， 造成全量同步失败。 对应日志如下：</li></ul><img src="/assets/image-20230402175335595-5Ypm-zUI.png" alt="image-20230402175335595" style="zoom:50%;"><p>每个服务器在刚开始进行复制的时候，都需要与主服务器进行一次完整同步。完整同步的命令是 sync 和 psync。当数据量较大时，会对主节点和从节点造成很大的网络开销。</p><p>从节点日志：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>83156:S 02 Apr 2023 17:33:07.077 * Connecting to MASTER 127.0.0.1:6379</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.077 * MASTER &lt;-&gt; REPLICA sync started</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.077 * Non blocking connect for SYNC fired the event.</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.077 * Master replied to PING, replication can continue...</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.077 * Trying a partial resynchronization (request 34d39a331978a925fc9d138919ce80f1f023fc66:99).</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.080 * Full resync from master: fc318b44d1f853caaed26b6e608e55d1a09ad2de:0</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.080 * Discarding previously cached master state.</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.149 * MASTER &lt;-&gt; REPLICA sync: receiving 193 bytes from master to disk</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.149 * MASTER &lt;-&gt; REPLICA sync: Flushing old data</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.149 * MASTER &lt;-&gt; REPLICA sync: Loading DB in memory</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.150 * Loading RDB produced by version 6.2.11</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.150 * RDB age 0 seconds</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.150 * RDB memory usage when created 2.06 Mb</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.150 # Done loading RDB, keys loaded: 1, keys expired: 0.</span></span>
<span class="line"><span>83156:S 02 Apr 2023 17:33:07.150 * MASTER &lt;-&gt; REPLICA sync: Finished with success</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>主节点日志：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>83133:M 02 Apr 2023 17:33:07.077 * Replica 127.0.0.1:10086 asks for synchronization</span></span>
<span class="line"><span>83133:M 02 Apr 2023 17:33:07.077 * Partial resynchronization not accepted: Replication ID mismatch (Replica asked for &#39;34d39a331978a925fc9d138919ce80f1f023fc66&#39;, my replication IDs are &#39;baea43cd0b43dde3c2272c616c53431392fd24af&#39; and &#39;0000000000000000000000000000000000000000&#39;)</span></span>
<span class="line"><span>83133:M 02 Apr 2023 17:33:07.077 * Replication backlog created, my new replication IDs are &#39;fc318b44d1f853caaed26b6e608e55d1a09ad2de&#39; and &#39;0000000000000000000000000000000000000000&#39;</span></span>
<span class="line"><span>83133:M 02 Apr 2023 17:33:07.077 * Starting BGSAVE for SYNC with target: disk</span></span>
<span class="line"><span>83133:M 02 Apr 2023 17:33:07.080 * Background saving started by pid 83157</span></span>
<span class="line"><span>83157:C 02 Apr 2023 17:33:07.081 * DB saved on disk</span></span>
<span class="line"><span>83133:M 02 Apr 2023 17:33:07.149 * Background saving terminated with success</span></span>
<span class="line"><span>83133:M 02 Apr 2023 17:33:07.149 * Synchronization with replica 127.0.0.1:10086 succeede</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>从上面的日志可以简单看到主节点和从节点做了什么事情。</p><p>需要注意， 对于数据量较大的主节点， 比如生成的 RDB 文件超过 6GB 以上时要格外小心。 传输文件这一步操作非常耗时， 速度取决于主从节点之间网络带宽， 通过细致分析 Full resync 和 MASTER &lt;-&gt; REPLICA （旧版本是 MASTER &lt;-&gt; SLAVE）这两行日志的时间差， 可以算出 RDB 文件从创建到传输完毕消耗的总时间。 如果总时间超过 repl-timeout 所配置的值（默认 60秒）， 从节点将放弃接受 RDB 文件并清理已经下载的临时文件， 导致全量复制失败， 此时从节点打印如下日志：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>83133:M 02 Apr 2023 17:33:10.149 # Timeout receiving bulk data from MASTER... If the problem persists try to set the &#39;repl-timeout&#39; parameter in redis.conf to a larger</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>针对数据量较大的节点， 建议调大 repl-timeout 参数防止出现全量同步数据超时。</p><p>完整复制的时间开销如下：</p><ul><li>主节点 bgsave 时间。</li><li>RDB 文件网络传输时间。</li><li>从节点清空数据时间。</li><li>从节点加载 RDB 的时间。</li><li>可能的 AOF 重写时间</li></ul><h4 id="复制偏移量和复制积压缓冲区" tabindex="-1"><a class="header-anchor" href="#复制偏移量和复制积压缓冲区"><span>复制偏移量和复制积压缓冲区</span></a></h4><p><strong>（1）主从节点各自的复制偏移量</strong></p><p>参与复制的主从节点都会维护自身复制偏移量。 主节点 在处理完写入命令后， 会把命令的字节长度做累加记录， 统计信息在 info relication中的 master_repl_offset 指标中</p><p>从节点每秒上报自身的复制偏移量给主节点，因此主节点也会保存从节点的复制偏移量</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1:6379&gt; info replication</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Replication</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">role:master</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">connected_slaves:1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave0:</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">ip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">port</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">10086,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">state</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">online,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">offset</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">7924,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">lag</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">0  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 从节点上报的复制偏移量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">.....</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_repl_offset:7924 									</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 主节点的复制偏移量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">.....</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>从节点在接收到主节点发送的命令后， 也会累加记录自身的偏移量。 统计信息在 info relication 中的 slave_repl_offset 指标中：</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1:10086&gt; info replication</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Replication</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">role:slave</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">.....</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave_read_repl_offset:7672</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave_repl_offset:7672</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">.....</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通过对比主从节点的复制偏移量， 可以判断主从节点数据是否一致。</p><p><strong>（2）复制积压缓冲区</strong></p><p>复制积压缓冲区是保存在主节点上的一个固定长度的队列，默认大小是 1MB，当主节点有链接的从节点时创建，这时主节点响应写命令时，不但会把命令发送给从节点，还会写入复制积压缓冲区。</p><p>复制积压缓冲区是一个 FIFO 的定长队列，所以能实现保存最近已复制数据的功能，用于部分复制和复制命令丢失的数据补救。复制缓冲区相关统计保存在主节点的 info replication 中：</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1:6379&gt; info replication</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Replication</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">.....</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_active:1				</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 是否开启复制积压缓冲区</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_size:1048576			</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 缓冲区的最大长度（字节）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_first_byte_offset:1	</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 起始偏移量，计算当前缓冲区的可用范围</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_histlen:7924			</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 已保存数据的有效长度</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以通过 repl-backlog-size 设置复制积压缓冲区的大小。</p><p><strong>（3） psync 命令</strong></p><blockquote><p><a href="https://redis.io/commands/psync/" target="_blank" rel="noopener noreferrer">https://redis.io/commands/psync/</a></p></blockquote><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>PSYNC replicationid offset</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>当从节点向主节点发送 PSYNC 命令时，主节点会根据自身的情况给从节点响应</p><ul><li>完整同步；</li><li>部分同步；</li><li>第三种情况是主节点的 Redis 版本低于 2.8，无法识别psync 命令，从节点将发送旧版的 sync 命令触发完整同步；</li></ul><h4 id="部分同步" tabindex="-1"><a class="header-anchor" href="#部分同步"><span>部分同步</span></a></h4><p>当因故障下线的从节点重新上线时，主从节点的数据一般都不再一致，因此它们必须进行同步，让主从节点再次一致状态。Redis 2.8 之前，重新同步的操作都是通过直接进行完整同步来实现的，但是这种重新同步的方式在从节点短暂下线的情况下是非常浪费资源的，因为下线后可能就只写了一个命令。</p><p>为了解决这个问题，Redis 2.8 版本提供了一个新的同步方式，主要是 PSYNC 命令：</p><ul><li>当一个 Redis 节点成为另一个节点的主节点时，它会把每个被执行的写命令都记录到一个特定长度的 FIFO 队列中；</li><li>当下线的从节点尝试重新连接主节点的时候，主节点将检查从节点下线期间，被执行的那些写命令是否仍然保存在队列里面。 <ul><li>如果在队列里面，那么主节点就会直接把从节点缺失的那些写命令发送给从节点执行，从节点通过执行这些写命令就可以重新和主节点保持一致的状态；</li><li>如果不在队列里面，那么主从服务器会进行一次完整同步；</li></ul></li></ul><img src="/assets/image-20230402180412596-BD7U2fjd.png" alt="image-20230402180412596" style="zoom:50%;"><p>部分同步的流程</p><ul><li><p>当主从节点之间网络出现中断时，如果超过了 repl-timeout 时间，主节点会认为从将诶点故障并中断复制连接</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>83133:M 02 Apr 2023 18:05:18.660 # Connection with replica 127.0.0.1:10086 lost.</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>如果此次从节点没有宕机，也会打印连接丢失日志</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>85503:S 02 Apr 2023 18:08:52.177 # Connection with master lost.</span></span>
<span class="line"><span>85503:S 02 Apr 2023 18:08:52.177 * Caching the disconnected master state.</span></span>
<span class="line"><span>85503:S 02 Apr 2023 18:08:52.177 * Reconnecting to MASTER 127.0.0.1:6379</span></span>
<span class="line"><span>85503:S 02 Apr 2023 18:08:52.177 * MASTER &lt;-&gt; REPLICA sync started</span></span>
<span class="line"><span>85503:S 02 Apr 2023 18:08:52.177 # Error condition on socket for SYNC: Connection refused</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>主从连接中断期间主节点依然响应命令，但是因为复制连接中断命令无法发送给从节点，不过主节点内部存在的复制积压缓冲区，依然可以保存最近一段时间的写命令数据，默认最大缓存 1MB。</p></li><li><p>当主从节点网络恢复后，从节点会再次连接上主节点，</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>85503:S 02 Apr 2023 18:09:44.039 * Connecting to MASTER 127.0.0.1:6379</span></span>
<span class="line"><span>85503:S 02 Apr 2023 18:09:44.039 * MASTER &lt;-&gt; REPLICA sync started</span></span>
<span class="line"><span>85503:S 02 Apr 2023 18:09:44.039 * Non blocking connect for SYNC fired the event.</span></span>
<span class="line"><span>85503:S 02 Apr 2023 18:09:44.039 * Master replied to PING, replication can continue...</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的复制 id。因此会把它们当做 psync 参数发送给主节点，要求就行部分同步操作，日志如下：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>85503:S 02 Apr 2023 18:09:44.040 * Trying a partial resynchronization (request fc318b44d1f853caaed26b6e608e55d1a09ad2de:2689).</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li><li><p>主节点接到 psync 命令后首先核对参数复制 id 是否与自身一致，如果一致则说明之前复制的就是当前主节点。之后根据参数 offset 在自身复制积压缓冲区中查找，如果偏移量之后的数据存在缓冲区中，则对从节点响应可以进行部分同步。从节点接到回复后打印日志如下：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>85503:S 02 Apr 2023 18:09:44.041 * Successful partial resynchronization with master.</span></span>
<span class="line"><span>85503:S 02 Apr 2023 18:09:44.041 * MASTER &lt;-&gt; REPLICA sync: Master accepted a Partial Resynchronization.</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。发送的数据量可以在主节点的日志中获取，如下所示</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>82913:M 02 Apr 2023 18:09:44.031 * Replica 127.0.0.1:10086 asks for synchronization</span></span>
<span class="line"><span>82913:M 02 Apr 2023 18:09:44.031 * Partial resynchronization request from 127.0.0.1:10086 accepted. Sending 39 bytes of backlog starting from offset 2689.</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><h4 id="在线异步更新" tabindex="-1"><a class="header-anchor" href="#在线异步更新"><span>在线异步更新</span></a></h4><p>当主节点把当前的数据同步给从节点后，便完成了复制的建立流程。接下来每当主节点执行一个写命令后，就会将相同的写命令或者具有相同效果的写命令发送给从节点执行；</p><p>因为是异步更新，所以主节点在执行完写命令之后直到从节点也执行完相同写命令的这段时间里，主从节点的数据库将出现短暂的不一致，因此要求强一致性的程序可能需要直接读取主节点的数据。所以 Redis 的复制功能是无法杜绝不一致的。</p><p>我们可以通过 info replication 查看复制延迟了多少</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1:6379&gt; info replication</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Replication</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">role:master</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">connected_slaves:1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave0:</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">ip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">port</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">10086,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">state</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">online,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">offset</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">1778,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">lag</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">0</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_failover_state:no-failover</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_replid:8909d9d2679658bbd539da23ca2f242428fcb25d</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_replid2:0000000000000000000000000000000000000000</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_repl_offset:1778</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">second_repl_offset:-1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_active:1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_size:1048576</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_first_byte_offset:1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_histlen:1778</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以看 slave0 的信息，记录了从节点的 ip 、端口、从节点的状态、当前从节点的复制偏移量、lag 表示延迟。</p><p>master_repl_offset 表示当前主节点的复制偏移量，两者的差值就是当前从节点的复制偏移量。</p><h4 id="心跳保持" tabindex="-1"><a class="header-anchor" href="#心跳保持"><span>心跳保持</span></a></h4><p>从节点通过命令 <code>REPLCONF ACK &lt;reploff&gt;</code> 每秒向主服务器汇报自己的复制偏移量，主节点存储接收到该命令的时间，以此作为检测从节点是否有效的标准。repl_timeout 表示主从服务器超时时间，用户可通过参数repl-timeout配置，默认为60，单位秒，超过此时间则认为主从服务器之间的连接出现故障，从服务器会主动断开连接。</p><p>主从心跳机制：</p><ul><li>主从节点都有自己的心跳检测机制，各自模拟成对方的客户端进行通信，通过 client list 命令可以查看复制相关的客户端信息，主节点的连接状态为 flags=M，从节点连接状态为 flags=S；</li><li>主节点默认每隔 10 秒对从节点发送 ping 命令，判断从节点的存活性和连接状态。可通过 repl-ping-slave-period 设置发送频率；</li><li>从节点在主线程中每隔 1 秒发送 <code>REPLCONF ACK &lt;reploff&gt;</code> 命令，向主服务器汇报自己的复制偏移量；</li></ul><p><code>REPLCONF ACK &lt;reploff&gt;</code> 命令的作用是：</p><ul><li>实时检测主从节点网络状态；</li><li>上报自身复制偏移量，检查复制数据是否丢失，如果从节点数据丢失，再从主节点的复制缓冲区中拉取丢失数据；</li><li>实现保证从节点的数量和延迟性功能，通过 min-slaves-to-write 和 min-slaves-max-lag 参数配置定义；</li></ul><h4 id="无盘复制" tabindex="-1"><a class="header-anchor" href="#无盘复制"><span>无盘复制</span></a></h4><p>前面说过，主节点在进行完整同步的时候，需要在本地创建 RDB 文件，然后通过套接字将这个 RDB 文件传输给从节点。但是如果主节点创建 RDB 文件也是一个耗性能的操作。</p><p>Redis 2.8.18 引入误判复制操作（diskless replication），开启了这个特性的主节点在接收到 replicaof / slaveof 命令时将不再在本地创建 RDB 文件，而是会 fork 一个子进程，然后由子进程通过套接字直接将 RDB 文件写入从节点，这样主节点就可以在不创建 RDB 文件的情况下，完成和从节点的数据同步。</p><p>配置项 repl-diskless-sync 开启无盘复制</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>repl-diskless-sync yes</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="复制可能出现的问题" tabindex="-1"><a class="header-anchor" href="#复制可能出现的问题"><span>复制可能出现的问题</span></a></h2><h3 id="主从数据延迟" tabindex="-1"><a class="header-anchor" href="#主从数据延迟"><span>主从数据延迟</span></a></h3><p>因为复制是通过异步操作的，所以主从节点之后肯定会有数据不一致的情况。延迟取决于网络带宽和命令阻塞的情况，需要业务场景允许短时间的数据延迟。为了尽可能的降低数据不一致出现的概率，Redis 从 2.8 开始引入了两个配置项</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>min-slaves-to-write 3</span></span>
<span class="line"><span>min-slaves-max-lag 10</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>配置这两个选项后，主节点只会在从节点大于等于 min-slaves-to-write 的值，并且这些从节点与主节点最后一次成功通信的时间间隔不超过 min-slaves-max-lag 的时候才会执行写命令。</p><p>这样我们可以让主节点只在主从服务器连接良好的情况下执行写命令。这样可以有效减少因为主从节点连接不稳定而导致的数据不一致，并降低因为没有从节点可用而导致数据丢失的可能性。</p><p>对应于无法容忍大量延迟场景， 可以编写外部监控程序监听主从节点的复制偏移量， 当延迟较大时触发报警或者通知客户端避免读取延迟过高的从节点。</p><p>在主节点执行 info replication 命令中：</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1:6379&gt; info replication</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Replication</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">role:master</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">connected_slaves:2</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave0:</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">ip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">port</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">10086,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">state</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">online,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">offset</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">23447,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">lag</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">0</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">slave1:</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">ip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">127.0.0.1,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">port</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">0,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">state</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">online,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">offset</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">0,</span><span style="--shiki-light:#E45649;--shiki-dark:#C678DD;">lag</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">15417</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_failover_state:no-failover</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_replid:8909d9d2679658bbd539da23ca2f242428fcb25d</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_replid2:0000000000000000000000000000000000000000</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">master_repl_offset:23447</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">second_repl_offset:-1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_active:1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_size:1048576</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_first_byte_offset:1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">repl_backlog_histlen:23447</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>master_repl_offset 是主节点的复制偏移量，slave0 和 slave1 中存的是从节点的一些信息。可以监控主从节点的复制偏移量的差值。</p><h3 id="从节点的过期数据" tabindex="-1"><a class="header-anchor" href="#从节点的过期数据"><span>从节点的过期数据</span></a></h3><p>当主节点存储大量设置超时的数据时，Redis 需要维护过期数据的删除策略。主要是惰性删除和定时删除。</p><ul><li>惰性删除：主节点每次处理读命令时，会检查键是否超时，如果超时则执行 del 命令删除键对象，之后 del 命令也会异步发送给从节点。需要注意的是为了保证复制的一致性，从节点自身永远不会主动删除超时数据；</li><li>定时删除：Redis 主节点在内部定时任务会循环采样一定数量的键，当发现采样的键过期时执行 del 命令，之后再同步给从节点；</li></ul><p>阐述问题：</p><ul><li>从节点不会使键过期，而是等待主节点使键过期。当主节点使键过期（或由于 LRU 而将其逐出）时，它会合成一个<a href="https://redis.io/commands/del" target="_blank" rel="noopener noreferrer"><code>DEL</code></a>命令，该命令将传输到所有从节点；</li><li>如果此时数据大量超时，主机点的采样速度跟不上过期速度且主节点没有读取过期键的操作，那么从节点将无法收到 del 命令。这是在从节点上可以读取到已经超时的数据。Redis 在 3.2 版本解决了这个问题，从节点读取数据之前会检查键的过期时间来决定是否返回数据；</li></ul><h3 id="主从配置不一致" tabindex="-1"><a class="header-anchor" href="#主从配置不一致"><span>主从配置不一致</span></a></h3><p>高版本的 Redis 默认情况下，从节点将忽略 maxmemory（除非它在故障转移后或手动提升为主）。这意味着键的逐出将由主节点处理，将 DEL 命令发送到从节点，作为主服节点端的键逐出。</p><p>要更改此行为，您可以允许副本不忽略 maxmemory，要使用的配置指令是：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>replica-ignore-maxmemory no</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>主从配置不一致是一个容易忽视的问题。 对于有些配置主从之间是可以不一致， 比如： 主节点关闭 AOF 在从节点开启。 但对于内存相关的配置必须要一致， 比如 maxmemory， hash-max-ziplist-entries 等参数。 当配置的 maxmemory 从节点小于主节点， 如果复制的数据量超过从节点 maxmemory 时， 它会根据 maxmemory-policy 策略进行内存溢出控制， 此时从节点数据已经丢失， 但主从复制流程依然正常进行， 复制偏移量也正常。 修复这类问题也只能手动进行全量复制。 当压缩列表相关参数不一致时， 虽然主从节点存储的数据一致但实际内存占用情况差异会比较大。</p><h3 id="避免完整同步" tabindex="-1"><a class="header-anchor" href="#避免完整同步"><span>避免完整同步</span></a></h3><p>因为完整同步是一个非常耗性能的操作，第一次建立复制的时候应该在业务低峰期的时候进行。</p><p>当主从节点断开后，再次建立连接时从节点会发送 psync 到主节点请求部分同步，如果请求的复制偏移量不在复制积压缓冲区中，此时也会进行完整同步，所以针对这种情况需要根据网络中断时长， 写命令数据量分析出合理<br> 的积压缓冲区大小。 网络中断一般有闪断、 机房割接、 网络分区等情况。 这时网络中断的时长一般在分钟级。 写命令数据量可以统计高峰期主节点每秒 info replication 的 master_repl_offset 差值获取。积压缓冲区默认为1MB， 对于大流量场景显然不够， 这时需要增大积压缓冲区。</p><p>配置项：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>repl-backlog-size 1mb</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="避免复制风暴" tabindex="-1"><a class="header-anchor" href="#避免复制风暴"><span>避免复制风暴</span></a></h3><p>复制风暴是指大量从节点对同一主节点或者对同一台机器的多个主节点短时间内发起全量复制的过程。 复制风暴对发起复制的主节点或者机器造成大量开销， 导致CPU、 内存、 带宽消耗。 因此我们应该分析出复制风暴发生的场景， 提前采用合理的方式规避。 规避方式有如下几个</p><p>单主节点复制风暴一般发生在主节点挂载多个从节点的场景。 当主节点重启恢复后， 从节点会发起全量复制流程， 这时主节点就会为从节点创建RDB快照， 如果在快照创建完毕之前， 有多个从节点都尝试与主节点进行全量同步， 那么其他从节点将共享这份RDB快照。 这点Redis做了优化， 有效避免了创建多个快照。 但是， 同时向多个从节点发送RDB快照， 可能使主节点的网络带宽消耗严重， 造成主节点的延迟变大， 极端情况会发生主从节点<br> 连接断开， 导致复制失败。</p><p>Redis 做的优化：</p><ul><li>如果主节点在收到 replicaof、slaveof 命令之前，已经创建了 RDB，并且它在创建这个 RDB 文件之后没有写命令，那么主节点直接向从节点发送已有的 RDB 文件。</li><li>如果在主节点创建 RDB 期间有多个从节点向主节点发送数据同步请求，那么主节点会将发生请求的从节点全部放到一个队列中，等到 RDB 文件创建完毕后，再把它发给队列中的所有从节点。</li></ul><p>解决方案首先可以减少主节点挂载从节点的数量，或者采用树状复制结构， 加入中间层从节点用来保护主节点，</p><img src="/assets/image-20230402230929991-CkKA-HAF.png" alt="image-20230402230929991" style="zoom:50%;"><h3 id="master-关闭持久性时复制的安全性" tabindex="-1"><a class="header-anchor" href="#master-关闭持久性时复制的安全性"><span>master 关闭持久性时复制的安全性</span></a></h3><p>在使用 Redis 复制的设置中，强烈建议在主节点和从节点中打开持久性。</p><p>假如主节点不打开持久性，假如由于非常慢的磁盘操作引起的延迟问题，主节点应该被配置为避免在脱机后**自动重启。**因为主节点没有保存持久化文件，它重启后数据库都是空的，这时所有的从节点都会发起一次全量同步，这样搞的所有从节点都没数据了。</p><ol><li><p>假如节点 A 充当主节点，持久性被关闭，节点 B 和 C 从节点 A 复制；</p></li><li><p>假如节点 A 崩溃了，假如配置了自动重启系统的功能，可以重启进程。但是主节点 A 由于持久性关闭了，因此节点会以空数据集重新启动；</p></li><li><p>节点 B 和 C 将从空的节点 A 进行复制，因此它们将从节点的数据都清空了；</p></li></ol><p>当 Redis Sentinel 用于高可用性时，同时关闭 master 上的持久性以及进程的自动重启是危险的。例如，master 可以足够快地重新启动，以使 Sentinel 无法检测到故障，从而发生上述故障模式。</p></div><!----><!----><!--[--><h2 id="doc-contributors" tabindex="-1"><a href="#doc-contributors" class="header-anchor"><span>Contributors</span></a></h2><div class="vp-contributors"><span target="_blank" rel="noreferrer" class="vp-contributor"><!----><span class="vp-contributor-name">Dylan Kwok</span></span></div><!--]--></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/guosgbin/vuepress-blog/edit/main/src/Redis/Redis复制.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank" iconsizing="both"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">Last Updated:</span><time class="vp-meta-info" datetime="2025-04-03T07:07:29.000Z" data-allow-mismatch>4/3/25, 7:07 AM</time></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/Redis/Redis%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85.html" aria-label="Redis发布订阅" iconsizing="both"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><!---->Redis发布订阅</div></a><a class="route-link auto-link next" href="/Redis/Redis%E5%A4%A7key%E5%92%8C%E7%83%ADkey%E9%97%AE%E9%A2%98.html" aria-label="Redis大key和热key问题" iconsizing="both"><div class="hint">Next<span class="arrow end"></span></div><div class="link">Redis大key和热key问题<!----></div></a></nav><div id="comment" class="giscus-wrapper input-top vp-comment" vp-comment style="display:block;"><div style="display: flex;
align-items: center;
justify-content: center;
height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);
--icon-size: 48px;
display: inline-block;
width: var(--icon-size);
height: var(--icon-size);
background-color: currentcolor;
-webkit-mask-image: var(--loading-icon);
mask-image: var(--loading-icon);
"></span></div></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">Default footer</div><div class="vp-copyright">Copyright © 2025 超威蓝猫 Dylan Kwok </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-DePq4ozi.js" defer></script>
  </body>
</html>
